from external.rag.rag_service import RagService
from external.youtube.transcript_service import TranscriptService
from external.youtube.video_detail_service import VideoDetailService
from external.youtube.youtube_video_service import VideoService
from external.youtube.youtube_comment_service import YoutubeCommentService
from domain.content_chunk.repository.content_chunk_repository import ContentChunkRepository
from domain.video.model.video import Video
from domain.channel.model.channel import Channel
from domain.comment.model.comment_type import CommentType
from core.enums.source_type import SourceTypeEnum
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from core.llm.prompt_template_manager import PromptTemplateManager
from external.youtube.trend_service import TrendService
from typing import List, Dict, Any
from datetime import datetime
import json
import logging
import time


logger = logging.getLogger(__name__)


class RagServiceImpl(RagService):
    def __init__(self):
        self.transcript_service = TranscriptService()
        self.video_detail_service = VideoDetailService()
        self.youtube_comment_service = YoutubeCommentService()
        self.content_chunk_repository = ContentChunkRepository()
        self.trend_service = TrendService()
        self.youtube_video_service = VideoService()
        self.llm = ChatOpenAI(model="gpt-4o-mini")
    
    def summarize_video(self, video_id: str) -> str:
        context = self.transcript_service.get_formatted_transcript(video_id)
        print("정리된 자막 = ", context)
        print()
        
        query = "유튜브 영상 자막을 기반으로 10초 단위 개요를 위의 형식에 따라 작성해주세요."
        return self.execute_llm_chain(context, query, PromptTemplateManager.get_video_summary_prompt())
    
    def classify_comment(self, comment: str) -> Dict[str, Any]:
        query = "유튜브 댓글을 분석하여 감정을 분류하고 백틱(```)이나 설명 없이 순수 JSON으로 출력해주세요."
        result = self.execute_llm_chain(comment, query, PromptTemplateManager.get_comment_reaction_prompt())
        print("LLM 응답 = ", result)

        try:
            clean_json_str = result.strip().replace("```json", "").replace("```", "")
            result_json = json.loads(clean_json_str)
            return {
                "comment_type": CommentType.from_emotion_code(result_json.get("emotion"))
            }
        except json.JSONDecodeError as e:
            print(f"JSON 파싱 오류: {e}, 원본 응답: {result}")
            return {
                "comment_type": CommentType.NEUTRAL
            }

    def summarize_comments(self, comments: str) -> List[str]:
        query = (
            "유튜브 댓글을 분석하여 요약하고 "
            "백틱(```)이나 설명 없이 순수 JSON으로 출력해주세요."
        )

        result = self.execute_llm_chain(
            comments, query, PromptTemplateManager.get_sumarlize_comment_prompt()
        )
        print("LLM 응답 = ", result)

        try:
            clean_json_str = result.strip().replace("```json", "").replace("```", "")
            result_list = json.loads(clean_json_str)
            contents = [item["content"] for item in result_list if isinstance(item, dict) and "content" in item]
            return contents
        except json.JSONDecodeError as e:
            print(f"JSON 파싱 오류: {e}, 원본 응답: {result}")
            return ["댓글 요약을 생성할 수 없습니다."]

    async def analyze_idea(self, video: Video, channel: Channel, summary: str="") -> List[Dict[str, Any]]:
        try:
            # 0. 영상 내용 참고
            sliced_summary = summary[:200]

            # 1. 내 채널, 내 영상
            origin_context = f"""
            - 분석 영상 제목: {video.title}
            - 분석 영상 설명: {video.description}
            - 분석 영상 카테고리 : {video.video_category.name}
            - 채널명: {channel.name}
            - 컨셉: {channel.concept}
            - 타겟 시청자: {channel.target}
            - 내용 : {sliced_summary}
            """
            logging.info("아이디어 내 채널 확인 : %s", origin_context)

            # 2. 인기 동영상 목록 유튜브 호출 (YouTube API)
            api_start = time.time()
            logger.info("📱 YouTube 인기 동영상 API 호출 중...")
            category_id = video.video_category.value
            popular_videos = self.youtube_video_service.get_category_popular(category_id)
            api_time = time.time() - api_start
            logger.info(f"📱 YouTube 인기 동영상 API 호출 완료 ({api_time:.2f}초) - {len(popular_videos)}개 영상")

            # 3. 텍스트로 변환하여 Vector DB에 저장
            for popular in popular_videos:
                pop_video_text = f"""제목: {popular['video_title']}, 설명: {popular['video_description']},태그: {popular['video_hash_tag']}"""
                await self.content_chunk_repository.save_context(
                    source_type=SourceTypeEnum.IDEA_RECOMMENDATION,
                    source_id=video.id,
                    context=pop_video_text)

            # 4. 영상과 의미적으로 가장 유사한 '인기 영상' 청크를 검색 (Vector DB)
            search_start = time.time()
            logger.info("🔍 유사 인기 영상 벡터 검색 중...")
            query_text = f"제목: {video.title}, 설명: {video.description}, 카테고리: {video.video_category.name}"
            video_embedding = await self.content_chunk_repository.generate_embedding(query_text)
            meta_data = {"query_embedding": str(video_embedding)}

            similar_chunks = await self.content_chunk_repository.search_similar_by_embedding(
                SourceTypeEnum.IDEA_RECOMMENDATION, metadata=meta_data, limit=5
            )
            search_time = time.time() - search_start
            logger.info(f"🔍 유사 인기 영상 벡터 검색 완료 ({search_time:.2f}초) - {len(similar_chunks)}개 청크")

            # 5. 검색된 청크(내용)를 텍스트로
            popularity_context = "\n".join([chunk.get("content", "") for chunk in similar_chunks])

            # 프롬프트 생성 및 LLM 실행
            llm_start = time.time()
            logger.info("🤖 아이디어 생성 LLM 실행 중...")
            query = "트렌드 분석 후, 이 유튜브 영상과 관련된 새 컨텐츠에 대한 아이디어를 3개 생성해주세요."
            chain = PromptTemplateManager.get_idea_prompt | self.llm
            result_str = await chain.ainvoke({
                "query": query,
                "origin": origin_context,
                "popularity": popularity_context
            })
            llm_time = time.time() - llm_start
            logger.info(f"🤖 아이디어 생성 LLM 실행 완료 ({llm_time:.2f}초)")

            # LLM의 응답 문자열을 JSON 파싱
            clean_json_str = result_str.content.strip().replace("```json", "").replace("```", "")
            return json.loads(clean_json_str)
        except Exception as e:
            logger.error(f"아이디어 생성 중 오류 발생: {e!r}")
            raise e

    
    async def analyze_algorithm_optimization(self, video_id: str, skip_vector_save: bool = False) -> str:
        """
        유튜브 알고리즘 최적화 분석
        
        Args:
            video_id: YouTube 영상 ID
            
        Returns:
            알고리즘 최적화 분석 결과
        """
        try:
            # 영상 상세 정보 조회 (YouTube API)
            video_start = time.time()
            logger.info("📹 YouTube 영상 상세 정보 API 호출 중...")
            video_details = self.video_detail_service.get_video_details(video_id)
            video_time = time.time() - video_start
            logger.info(f"📹 YouTube 영상 상세 정보 API 호출 완료 ({video_time:.2f}초)")
            
            # 채널 정보 조회 (YouTube API)
            channel_id = video_details.get('channelId')
            
            channel_stats = {}
            if channel_id:
                channel_start = time.time()
                logger.info("📺 YouTube 채널 통계 API 호출 중...")
                channel_stats = self.video_detail_service.get_channel_stats(channel_id)
                channel_time = time.time() - channel_start
                logger.info(f"📺 YouTube 채널 통계 API 호출 완료 ({channel_time:.2f}초)")
            
            # 분석에 필요한 데이터 구조화
            optimization_data = {
                "video": {
                    "title": video_details.get('title', ''),
                    "description": video_details.get('description', ''),
                    "tags": video_details.get('tags', []),
                    "publishedAt": video_details.get('publishedAt', ''),
                    "duration": video_details.get('duration', ''),
                    "viewCount": video_details.get('viewCount', 0),
                    "likeCount": video_details.get('likeCount', 0),
                    "commentCount": video_details.get('commentCount', 0),
                    "thumbnails": video_details.get('thumbnails', {})
                },
                "channel": {
                    "name": video_details.get('channelTitle', ''),
                    "subscriberCount": channel_stats.get('subscriberCount', 0),
                    "totalViewCount": channel_stats.get('viewCount', 0),
                    "totalVideoCount": channel_stats.get('videoCount', 0)
                }
            }
            
            # JSON 형식으로 context 생성
            context = json.dumps(optimization_data, ensure_ascii=False, indent=2)
            
            # 유사한 이전 알고리즘 최적화 분석 사례 검색 (skip_vector_save가 False인 경우만)
            if not skip_vector_save:
                query_text = f"제목: {video_details.get('title', '')}, 설명: {video_details.get('description', '')[:200]}"
                similar_chunks = await self.content_chunk_repository.search_similar_optimization(
                    query_text=query_text,
                    limit=3
                )
                
                # 이전 분석 사례가 있으면 context에 추가
                if similar_chunks:
                    previous_cases = "\n\n---\n\n".join([chunk.get("content", "") for chunk in similar_chunks])
                    context += f"\n\n## 유사 영상의 이전 최적화 분석 사례:\n{previous_cases}"
            
            query = "이 유튜브 영상의 알고리즘 최적화 상태를 분석하고 구체적인 개선 방안을 제시해주세요."
            
            # 프롬프트 템플릿 가져오기 및 LLM 실행
            llm_start = time.time()
            prompt_template = PromptTemplateManager.get_algorithm_optimization_prompt()
            result = self.execute_llm_chain(context, query, prompt_template)
            llm_time = time.time() - llm_start
            logger.info(f"🤖 알고리즘 최적화 LLM 실행 완료 ({llm_time:.2f}초)")
            
            return result
        
        except Exception as e:
            logger.error(f"알고리즘 최적화 분석 중 오류 발생: {e}")
            raise e
            

    def analyze_realtime_trends(self, limit: int = 5, geo: str = "KR") -> Dict:
        """
        실시간 트렌드를 분석하여 YouTube 콘텐츠에 적합한 형태로 반환
        
        Args:
            limit: 분석할 트렌드 개수 (최대 5개)
            geo: 지역 코드 (기본값: KR)
            
        Returns:
            분석된 트렌드 정보
        """
        # 1. Google Trends에서 실시간 트렌드 가져오기 (Google Trends API)
        trends_start = time.time()
        logger.info("📈 Google Trends 실시간 트렌드 API 호출 중...")
        raw_trends = self.trend_service.get_realtime_trends(limit=limit*2, geo=geo)  # 여유있게 가져오기
        trends_time = time.time() - trends_start
        logger.info(f"📈 Google Trends 실시간 트렌드 API 호출 완료 ({trends_time:.2f}초) - {len(raw_trends) if raw_trends else 0}개 트렌드")
        
        if not raw_trends:
            return {"error": "트렌드 데이터를 가져올 수 없습니다."}
        
        current_date = datetime.now().strftime("%Y년 %m월 %d일")
        
        # 3. Context 구성
        context = {
            "trends_data": raw_trends,
            "current_date": current_date,
            "region": geo
        }
        
        # 4. LLM에게 분석 요청
        query = f"실시간 트렌드 중 YouTube 콘텐츠로 적합한 상위 {limit}개를 선정하고 분석해주세요."
        prompt_template = PromptTemplateManager.get_trend_analysis_prompt()
        
        # 5. LLM 실행 및 결과 파싱
        llm_start = time.time()
        logger.info("🤖 실시간 트렌드 분석 LLM 실행 중...")
        result_str = self.execute_llm_chain(
            context=json.dumps(context, ensure_ascii=False),
            query=query,
            prompt_template_str=prompt_template
        )
        llm_time = time.time() - llm_start
        logger.info(f"🤖 실시간 트렌드 분석 LLM 실행 완료 ({llm_time:.2f}초)")
        
        try:
            clean_json_str = result_str.strip().replace("```json", "").replace("```", "")
            result = json.loads(clean_json_str)
            return result
        except json.JSONDecodeError:
            return {"error": "결과 파싱 오류", "raw_result": result_str}
    
    

    def analyze_channel_trends(
        self,
        channel_concept: str,
        target_audience: str

    ) -> Dict:
        """
        채널 맞춤형 트렌드를 생성하고 분석
        
        Args:
            channel_concept: 채널 컨셉
            target_audience: 타겟 시청자
            
        Returns:
            채널 맞춤형 트렌드 분석 결과
        """
        # 1. Context 구성 (채널 정보)
        current_date = datetime.now().strftime("%Y년 %m월 %d일")
        
        context = {
            "channel_concept": channel_concept,
            "target_audience": target_audience,
            "current_date": current_date
        }
        
        # 2. LLM에게 분석 요청
        query = "채널에 최적화된 트렌드 키워드 5개를 생성하고 분석해주세요."
        prompt_template = PromptTemplateManager.get_channel_customized_trend_prompt()
        
        # 3. 채널 맞춤형 트렌드를 위한 특별 처리
        documents = [Document(page_content=json.dumps(context, ensure_ascii=False))]
        
        # 필요한 모든 변수를 포함한 프롬프트 템플릿 생성
        prompt = PromptTemplate(
            input_variables=["input", "context", "channel_concept", "target_audience", "current_date"],
            template=prompt_template
        )
        
        chat_prompt = ChatPromptTemplate.from_messages([
            HumanMessagePromptTemplate(prompt=prompt)
        ])
        
        # 체인 실행
        llm_start = time.time()
        logger.info("🤖 채널 맞춤형 트렌드 분석 LLM 실행 중...")
        combine_chain = create_stuff_documents_chain(self.llm, chat_prompt)
        result_str = combine_chain.invoke({
            "input": query,
            "context": documents,
            "channel_concept": channel_concept,
            "target_audience": target_audience,
            "current_date": current_date
        })
        llm_time = time.time() - llm_start
        logger.info(f"🤖 채널 맞춤형 트렌드 분석 LLM 실행 완료 ({llm_time:.2f}초)")
        
        
        try:
            clean_json_str = result_str.strip().replace("```json", "").replace("```", "")
            result = json.loads(clean_json_str)
            return result
        except json.JSONDecodeError:
            return {"error": "결과 파싱 오류", "raw_result": result_str}



    def execute_llm_chain(self, context: str, query: str, prompt_template_str: str) -> str:
        """
        LLM 체인을 실행하는 공통 메서드
        :param context: LLM에 제공할 정보(youtube api를 통해 가져온 자막 등)
        :param query: 사용자 질문
        :return: LLM의 응답
        """
        documents = [Document(page_content=context)]
        
        # 프롬프트 템플릿 생성
        prompt_template = PromptTemplate(
            input_variables=["input", "context"],
            template=prompt_template_str
        )

        chat_prompt = ChatPromptTemplate.from_messages([
            HumanMessagePromptTemplate(prompt=prompt_template)
        ])

        # 체인 조합 및 실행
        combine_chain = create_stuff_documents_chain(self.llm, chat_prompt)
        result = combine_chain.invoke({"input": query, "context": documents})
        return result
    
    def execute_llm_direct(self, prompt: str) -> str:
        """
        이미 완성된 프롬프트 문자열을 바로 LLM에 넣어 실행하는 함수

        :param prompt: 완성된 프롬프트 문자열
        :return: LLM의 응답
        """
        # self.llm이 직접 프롬프트 문자열을 받아 실행하는 함수라고 가정
        result = self.llm.invoke(prompt)
        return result.content
        